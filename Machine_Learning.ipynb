{"cells":[{"cell_type":"code","source":["spark"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["sc"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["sqlContext"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["<h4> Read in Loan data </h4>"],"metadata":{}},{"cell_type":"code","source":["loan_df = sqlContext.read.format(\"csv\").options(header = \"true\", inferschema = \"true\").load(\"/FileStore/tables/7oewn9wr1506610007136/lending_club_data-fbee9.csv\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["display(loan_df)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["<h4> Exploring Features </h4>"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\n#loan_pd_df = loan_df.toPandas()\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["display(loan_df.describe())"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["loan_df.columns"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["loan_df.printSchema()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["loan_df.cache()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["<h4> Look at distribution of grade data </h4>"],"metadata":{}},{"cell_type":"code","source":["#import matplotlib as plt\n#%matplotlib inline\n#grade_distribution = loan_df.['grade'].value_counts()\ngrade_distribution = loan_df.groupBy('grade').count()\ndisplay(grade_distribution)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["loan_df.createOrReplaceTempView('loan_tab')"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["<h4> Over half the loan grades are 'B or 'C' </h4>"],"metadata":{}},{"cell_type":"code","source":["display(spark.sql(\"select grade, count(*) as count from loan_tab group by grade order by count(*) desc\"))"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["<h4> Only a Small percentage of loanees own a home </h4>"],"metadata":{}},{"cell_type":"code","source":["display(loan_df.groupBy('home_ownership').count().sort(desc(\"count\")))"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["from pyspark.sql import functions as f\n\ndisplay(loan_df.groupBy('home_ownership').agg(f.count('*').alias('total')).sort(desc('total')))"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["<h4> Exploring Target Column 'Bad Loans' </h4>"],"metadata":{}},{"cell_type":"markdown","source":["<h5> Remapping it to be +1 and -1 so it is more intuitive. \n<p> \n<ul> \n<li> +1 -> safe </li>\n<li> -1 -> risky (bad loan) </li>\n</ul>\n</p>"],"metadata":{}},{"cell_type":"code","source":["loan_df = loan_df.withColumn('bad_loans', loan_df('bad_loans').map(lambda x : +1 if x==0 else -1))\n#loans = loans.remove_column('bad_loans')"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":24}],"metadata":{"name":"Machine_Learning","notebookId":2591315425395732},"nbformat":4,"nbformat_minor":0}
